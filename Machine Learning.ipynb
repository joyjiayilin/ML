{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8A0yIDCtJLa"
      },
      "source": [
        "# Homework 1 - Linear Regression\n",
        "\n",
        "## Dataset\n",
        "The dataset you will be using is about Life expectancy of different countries. We will explore how immunization factors, mortality factors, economic factors, social factors and other health related factors affect Life expectancy of a country.\n",
        "\n",
        "There are two data files: \"LifeExpectancy_training_modified.csv\" and \"LifeExpectancy_test_modified.csv\"<br/>\n",
        "Both files have the following fields, except Life_expectancy which is not available in \"LifeExpectancy_test_modified.csv\"\n",
        "\n",
        "Features :\n",
        "- Year : from 2002 to 2015\n",
        "- Status : Developed or Developing status\n",
        "- Adult_Mortality : Adult Mortality Rates of both sexes (probability of dying between 15 and 60 years per 1000 population)\n",
        "- Alcohol : Alcohol, recorded per capita (15+) consumption (in litres of pure alcohol)\n",
        "- percentage_expenditure : Expenditure on health as a percentage of Gross Domestic Product per capita(%)\n",
        "- BMI: Average Body Mass Index of entire population\n",
        "- Total_expenditure: General government expenditure on health as a percentage of total government expenditure (%)\n",
        "- Diphtheria: Diphtheria tetanus toxoid and pertussis (DTP3) immunization coverage among 1-year-olds (%)\n",
        "- HIV_AIDS: Deaths per 1000 live births HIV/AIDS (0-4 years)\n",
        "- GDP: Gross Domestic Product per capita (in USD)\n",
        "- Population\n",
        "- Income_composition_of_resources: Human Development Index in terms of income composition of resources (index ranging from 0 to 1)\n",
        "- Schooling: Number of years of Schooling(years)\n",
        "- Health_Index: Health index\n",
        "\n",
        "Target:\n",
        "- Life_expectancy: Life Expectancy in age\n",
        "\n",
        "\n",
        "Training dataset, \"LifeExpectancy_training_modified.csv\", contains 1064 rows and 15 columns. This is the training set containing both of the features and the target.<br/>\n",
        "Test dataset, \"LifeExpectancy_test_modified.csv\", contains 458 rows and 14 columns. This is the test set which only contains the features.<br/>\n",
        "\n",
        "Your goal is to predict Life expectancy based on the features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xwWTXsa30LLu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from statistics import mean\n",
        "from sklearn import datasets\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGLaGzbL0jdH"
      },
      "source": [
        "Load the training data \"LifeExpectancy_training_modified.csv\" in Colab and View the first 5 lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "id": "u5oaCEzI0se8",
        "outputId": "7b6afa4c-bea7-4fb9-d8e8-09991350d712"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3521bd5d-78a1-48bb-8c20-09ff0df1db95\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3521bd5d-78a1-48bb-8c20-09ff0df1db95\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viQgJ6uy03nd"
      },
      "outputs": [],
      "source": [
        "# Load the training data\n",
        "import io\n",
        "df_train = pd.read_csv(io.BytesIO(uploaded['LifeExpectancy_training_modified.csv']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTxYGeoSxcKs"
      },
      "outputs": [],
      "source": [
        "# Show the first 5 lines\n",
        "### WRITE CODE ###\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIRo3Da91IdF"
      },
      "source": [
        "## Data Exploration\n",
        "We can plot a histogram of the dataframe for the features except \"Status\" to understand their distributions. <br/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iemQk82B3Nam"
      },
      "outputs": [],
      "source": [
        "### WRITE CODE TO OBTAIN AND DISPLAY HISTOGRAMS ###\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Make a copy of the dataframe with the features except \"Status\"\n",
        "features_without_status = df_train.drop(columns=['Status'])\n",
        "\n",
        "# Plot a histogram for each of the rest of the features\n",
        "\n",
        "print(\"\\nDistributions:\")\n",
        "for column in features_without_status.columns:\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    if features_without_status[column].dtype == 'object':  # Categorical data\n",
        "        sns.countplot(x=features_without_status[column])\n",
        "    else:  # Numerical data\n",
        "        sns.histplot(features_without_status[column], kde=True)\n",
        "    plt.title(f'Distribution of {column}')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XD0AGPM5eaD"
      },
      "source": [
        "##### Q1. What can you infer from the histograms? <br/>\n",
        "From the histograms, we can infer that the features Total_expenditure and Schooling have an approximately normal distribution, the features Adult_Mortality, ALcohol, percentage_expenditure, HIV_AIDS, GDP, and Population are right-skewed, and the features Diphtheria, Income_composition_of_resources, and Life_expectancy are left-skewed, while the rest of the features do not display a clear distribution.\n",
        "The features with a highly skewed distribution might have a nonlinear relationship with another variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmq41MOV9Z8d"
      },
      "source": [
        "Compute the correlation matrix to get an understanding of the correlation between life_expectancy and the other features.<br/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXwoLj_QCXn1"
      },
      "outputs": [],
      "source": [
        "### WRITE CODE TO OBTAIN CORRELATION MATRIX ###\n",
        "\n",
        "# Compute the correlation matrix\n",
        "corr_matrix = df_train.corr()\n",
        "pd.DataFrame(corr_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmuZTzx29bkO"
      },
      "outputs": [],
      "source": [
        "# Correlation between life_expectancy and the other features\n",
        "corr_matrix = corr_matrix['Life_expectancy'].drop('Life_expectancy')\n",
        "pd.DataFrame(corr_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UpsTJyw97FZ"
      },
      "source": [
        "##### Answer the following questions:<br/>\n",
        "\n",
        "##### Q2. Why is the diagonal made up of 1's in the correlation matrix?<br/>\n",
        "Because the the number making up the diagonal of a correlation matrix is the correlation between a variable with itself, which should always be 1.\n",
        "\n",
        "##### Q3. Why is the matrix symmetric along diagonal?<br/>\n",
        "Because the correlation between a first and a second variable always equals to that between the second and the first.\n",
        "\n",
        "##### Q4. Looking at the correlation matrix, if you have to choose one predictor for a simple linear regression model with Life_expectancy as the outcome, which one would you choose and why? <br/>\n",
        "I would choose Income_composition_of_resources because it has the highest correlation with Life_expectancy, which is 0.756515, implying a strong linear relationship between Income_composition_of_resources and Life_expectancy.\n",
        "\n",
        "##### Q4.1. Is there any variable that does not make sense to you and why? <br/>\n",
        "The BMI variable does not make sense to me because the it has a relatively strong positive relationship with Life_expectancy with a correlation of 0.557677. This implies that the higher the BMI is, the higher the Life_expectancy, which is not the case. BMI should be within a certain range to improve life expectancy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYvGzY8Z-ni-"
      },
      "source": [
        "### Standardization of features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jhq-T3Ed-r8w"
      },
      "source": [
        "Feature standardization makes the values of each feature in the data have zero-mean and unit-variance. This method is widely used for normalization in many machine learning algorithms. The general method of calculation is to determine the distribution mean and standard deviation for each feature. Next we subtract the mean from each feature. Then we divide the values of each feature by its standard deviation.\n",
        "\n",
        "$x'$ = ($x$ - $\\bar{x}$)/$\\sigma$\n",
        "\n",
        "where $x$ is the original feature vector,\n",
        "$\\bar{x}$ is the mean of the feature vector and\n",
        "$\\sigma$ is its standard deviation.\n",
        "\n",
        "This is also called Z-score Normalization.\n",
        "\n",
        "Perform Z-score Normalization on the features (except \"Year\" and \"Status\") in both training and test set."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "HEIff9D0_cVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iD2UmlarDHY_"
      },
      "outputs": [],
      "source": [
        "# Load the test set \"LifeExpectancy_test_modified.csv\"\n",
        "import io\n",
        "df_test = pd.read_csv(io.BytesIO(uploaded['LifeExpectancy_test_modified.csv']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fb8uQ3FeOR16"
      },
      "outputs": [],
      "source": [
        "### WRITE CODE TO PERFORM Z-score Normalization ###\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Selecting numerical data\n",
        "numerical_data = df_train.drop(columns=['Year', 'Status', 'Life_expectancy'])\n",
        "\n",
        "# Applying StandardScaler\n",
        "scaler = StandardScaler()\n",
        "numerical_scaled = scaler.fit_transform(numerical_data)\n",
        "\n",
        "# Convert to DataFrame\n",
        "numerical_scaled_df_train = pd.DataFrame(numerical_scaled, columns=numerical_data.columns)\n",
        "\n",
        "# Display the first few rows of the scaled dataframe\n",
        "numerical_scaled_df_train.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZFwECDy2EDD"
      },
      "outputs": [],
      "source": [
        "# Selecting numerical data\n",
        "numerical_data = df_test.drop(columns=['Year', 'Status'])\n",
        "\n",
        "# Applying StandardScaler\n",
        "scaler = StandardScaler()\n",
        "numerical_scaled = scaler.fit_transform(numerical_data)\n",
        "\n",
        "# Convert to DataFrame\n",
        "numerical_scaled_df_test = pd.DataFrame(numerical_scaled, columns=numerical_data.columns)\n",
        "\n",
        "# Display the first few rows of the scaled dataframe\n",
        "numerical_scaled_df_test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwfacAsAFBbs"
      },
      "source": [
        "##### Q5. What are the advantages and disadvantages of using Z-score Normalization?<br/>\n",
        "Advantages include: It makes the data easier to interpret on a standardized scale; It does not change the distribution of the original data.\n",
        "Disadvantages include: Outliers might affect the normalization; It might not be applied to certain datasets, such as those with non-normal or highly-skewed distribution.\n",
        "\n",
        "##### Q6. In this dataset, do you need to use the Z-score Normalization? Explain.<br/>\n",
        "Yes. All the features are on different scales and units. Z-score Normalization makes it easier to compare the distributions between features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tr1XcvyFIcN"
      },
      "source": [
        "### One-Hot Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyyGwM3JFS4Y"
      },
      "source": [
        "\"Year\" and \"Status\" can only take discrete values. We need to perform one-hot encoding on discrete values for it to be processed in the model. One hot encoding is a process by which categorical variables are converted into a form that could be provided to ML algorithms to do a better job in prediction.\n",
        "Perform one-hot encoding on \"Year\" and \"Status\" and print the shape of your encoded array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcHWJHyl0WWH"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "### WRITE CODE TO PERFORM ONE-HOT CODING ON \"Year\" AND \"Status\" ###\n",
        "one_hot_training = df_train[['Year', 'Status']]\n",
        "\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "categorical_encoded_training = encoder.fit_transform(one_hot_training)\n",
        "\n",
        "categorical_encoded_df_training = pd.DataFrame(categorical_encoded_training, columns=encoder.get_feature_names_out(one_hot_training.columns))\n",
        "\n",
        "one_hot_test = df_test[['Year', 'Status']]\n",
        "\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "categorical_encoded_test = encoder.fit_transform(one_hot_test)\n",
        "\n",
        "categorical_encoded_df_test = pd.DataFrame(categorical_encoded_test, columns=encoder.get_feature_names_out(one_hot_test.columns))\n",
        "\n",
        "\n",
        "categorical_encoded_df_training.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZACvY1X1HSo"
      },
      "outputs": [],
      "source": [
        "categorical_encoded_df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OU9s-mc1TAm"
      },
      "outputs": [],
      "source": [
        "print(categorical_encoded_df_training.shape)\n",
        "print(categorical_encoded_df_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvbDqp5bJ-Xx"
      },
      "source": [
        "Q7. What are the other types of encodings and why did we use One-hot encoding for \"Year\" and \"Status\"?\n",
        "\n",
        "Ans- A few other types of encodings are:\n",
        "\n",
        "1. Label Encoding: Here we assign an integer to category. It is usually used for ordinal categorical variables.\n",
        "\n",
        "2. Binary Encoding: Here, first the categories are converted into integers, which are then converted into binary code. It is more efficient that one-hot encoding if the number of categories are high.\n",
        "\n",
        "3. Frequency Encoding: Here, each category is replaced with its frequency in the dataset.\n",
        "\n",
        "4. Mean Encoding: Here, each categorical value is replaced with the mean of the target variable for that category.\n",
        "\n",
        "\n",
        "One-hot encoding is the perfect choice for 'Status' because it prevents the model to establish a numerical relationship between the categories.\n",
        "\n",
        "Here 'Year' is encoded using One-hot encoding because it acts like nominal variable and not a numeric variable. Moreover, since there are only 14 distinct years in the dataset, the issue of high dimensionality can be managed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp5S0WizKI0g"
      },
      "source": [
        "## Multiple Linear Regression\n",
        "\n",
        "In the big data era, it is highly unlikely that we are interested in the effect of a single variable on another. To simultaneously account for the effects of multiple variables, we use multiple regression (which accounts for the covariances between predictors).\n",
        "\n",
        "While the algorithmic solution to multiple regression exists, it is easier to conceptualize in terms of linear algebra. The optimal $\\hat{\\beta}$ vector that minimizes the residual sum of squares is:\n",
        "\n",
        "$\\hat{\\beta} = (X^TX)^{-1}X^Ty $\n",
        "\n",
        "\n",
        "Perform multiple linear regression on the training dataset, where the outcome is \"Life_expectancy\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-saM1rTKjKH"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MY3vynA1gn7"
      },
      "outputs": [],
      "source": [
        "# Combine the df\n",
        "df_train_encoded = pd.concat([numerical_scaled_df_train, categorical_encoded_df_training, df_train['Life_expectancy']], axis=1, join='inner')\n",
        "df_test_encoded = pd.concat([numerical_scaled_df_test, categorical_encoded_df_test], axis=1, join='inner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTfbR3b-KoeW"
      },
      "outputs": [],
      "source": [
        "### Bulding and fitting the Multiple Linear Regression model###\n",
        "X = df_train_encoded.drop('Life_expectancy', axis=1)\n",
        "y = df_train_encoded['Life_expectancy']\n",
        "\n",
        "model = LinearRegression()\n",
        "\n",
        "model.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpQe-p3LLXgA"
      },
      "outputs": [],
      "source": [
        "### Evaluate the Linear Regression model by computing MSE on the training set###\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "y_train_pred = model.predict(X)\n",
        "mse_train = mean_squared_error(y, y_train_pred)\n",
        "\n",
        "print(\"Mean Squared Error on Training Set:\", mse_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2jOEvNiO84E"
      },
      "source": [
        "Q8. Print the value of coefficients and also the corresponding variable names for the coefficients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UeQVaLPcF2m"
      },
      "outputs": [],
      "source": [
        "coefficients = model.coef_\n",
        "\n",
        "# Get the feature names\n",
        "feature_names = X.columns\n",
        "\n",
        "coefficients_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Coefficient': coefficients\n",
        "})\n",
        "\n",
        "coefficients_df['Coefficient'] = coefficients_df['Coefficient'].apply(lambda x: f'{x:.4f}')\n",
        "\n",
        "coefficients_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Correlation HeatMap\n",
        "corr_matrix = df_train_encoded.corr()\n",
        "\n",
        "plt.figure(figsize=(20, 18))  # Size of the figure\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MZrLZ5sMW6O_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q18iLjtHX25r"
      },
      "source": [
        "Q9. Is there a problem of multicolinearity? Explain what you can do\n",
        "\n",
        "Ans- In the above correlation heatmap, leaving aside the diagonal, we can see that there is a high correlation between a few features. Therefore, there is a problem of multicolinearity.\n",
        "\n",
        "\n",
        "Multicollinearity can be dealt using the following methods:\n",
        "\n",
        "1. Remove the variables with high collinearity.\n",
        "2. Combine variables using feature engineering\n",
        "3. Use Principal Component Analysis\n",
        "4. Regularization like ridge and lasso can be applied"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ51d6d2YyPp"
      },
      "source": [
        "### Goodness of fit\n",
        "\n",
        "A model can always make predictions. But it is important to determine how good the model is.\n",
        "How do we know that our model captures the data well? When evaluating model fit, a good metric is $R^2$, which corresponds to the amount of variance explained by the model. The formula for $R^2$ is the following:\n",
        "\n",
        "$R^2$ = $1 - \\dfrac{RSS}{TSS}$<br/>\n",
        "where:<br/>\n",
        "$RSS = \\Sigma(y - \\hat{y})^2$<br/>\n",
        "$TSS = \\Sigma(y - \\bar{y})^2$<br/>\n",
        "\n",
        "$R^2$ is also one metric for comparing models against each other. It is intuitive to say that the model that explains more variation in the data is a better fit than one that explains less variation.\n",
        "\n",
        "Fill in the code for calculation of R2 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hr0giuHXY4J5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFiC_mfgY7m1"
      },
      "source": [
        "$R^2$ for model with \"Schooling\" as predictor and \"Life_expectancy\" as outcome"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIspp_FPaicb"
      },
      "outputs": [],
      "source": [
        "### WRITE CODE ###\n",
        "X = df_train_encoded[['Schooling']]\n",
        "y = df_train_encoded['Life_expectancy']\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X,y)\n",
        "\n",
        "y_pred = model.predict(X)\n",
        "r2 = r2_score(y,y_pred)\n",
        "# Print R2 score\n",
        "print('R^2 for model with \"Schooling\" as predictor and \"Life_expectancy\" as outcome is ', r2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fGTnWcobCc_"
      },
      "source": [
        "$R^2$ for model with \"Schooling\", \"Adult_Mortality\" as predictor and \"Life_expectancy\" as outcome"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqBXqRZlbjy7"
      },
      "outputs": [],
      "source": [
        "### WRITE CODE ###\n",
        "X = df_train_encoded[['Schooling', 'Adult_Mortality']]\n",
        "y = df_train_encoded['Life_expectancy']\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X,y)\n",
        "\n",
        "y_pred = model.predict(X)\n",
        "r2 = r2_score(y,y_pred)\n",
        "# Print R2 score\n",
        "print('R^2 for model with \"Schooling\", \"Adult_Mortality\" as predictor and \"Life_expectancy\" as outcome is ', r2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dE1PDtR0bVdX"
      },
      "source": [
        "$R^2$ for model with \"Schooling\",\"Adult_Mortality\" and \"Population\" as predictor and \"Life_expectancy\" as outcome"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WxDGrKqbyR2"
      },
      "outputs": [],
      "source": [
        "### WRITE CODE ###\n",
        "X = df_train_encoded[['Schooling', 'Adult_Mortality', 'Population']]\n",
        "y = df_train_encoded['Life_expectancy']\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X,y)\n",
        "\n",
        "y_pred = model.predict(X)\n",
        "r2 = r2_score(y,y_pred)\n",
        "# Print R2 score\n",
        "print('R^2 for model with \"Schooling\",\"Adult_Mortality\" and \"Population\" as predictor and \"Life_expectancy\" as outcome is ', r2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYdvN1CTcMuN"
      },
      "source": [
        "You can see $R^2$ is always going up as we keep adding features.\n",
        "\n",
        "This is one drawback of only using $R^2$ to evaluate your model. Adding predictors seems to always improve the predictive ability of your model, though it may not be true.\n",
        "\n",
        "That is to say, we are not necessarily interested in making a perfect prediciton of our training data. If we were, we would always use all of the predictors available. Rather, we would like to make a perfect prediction of our test data. In this case, adding all the predictors may not be a good idea due to the trade-off between bias and variance. Thus, we are interested in the most predictive features, in the hopes that we can create a simpler model that performs well in the future.\n",
        "\n",
        "This is why we consider another metric, Adjusted R2.\n",
        "The adjusted R-squared increases only if the new term improves the model more than would be expected by chance.\n",
        "\n",
        "\n",
        "$AdjustedR^2$ = $1 - \\dfrac{(1-R^2)(n-1)}{(n-p-1)}$<br/>\n",
        "where:<br/>\n",
        "n = number of samples<br/>\n",
        "p = number of features\n",
        "\n",
        "Fill in the code for calculation of adjusted R2 score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCqEwoDNcOgb"
      },
      "source": [
        "Adjusted $R^2$ for model with \"Schooling\" as predictor and \"Life_expectancy\" as outcome"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCgTtpskch0n"
      },
      "outputs": [],
      "source": [
        "### WRITE CODE ###\n",
        "X = df_train_encoded[['Schooling']]\n",
        "y = df_train_encoded['Life_expectancy']\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X,y)\n",
        "\n",
        "y_pred = model.predict(X)\n",
        "r2 = r2_score(y,y_pred)\n",
        "\n",
        "n = len(y)\n",
        "p = X.shape[1]\n",
        "\n",
        "adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
        "\n",
        "# Print Adjusted R2 score\n",
        "print('Adjusted R^2 for model with \"Schooling\" as predictor and \"Life_expectancy\" as outcome is ', adjusted_r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKLKf_ODc842"
      },
      "source": [
        "Adjusted $R^2$ for model with \"Schooling\", \"Adult_Mortality\" as predictor and \"Life_expectancy\" as outcome."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6j0eaIxdFoD"
      },
      "outputs": [],
      "source": [
        "### WRITE CODE ###\n",
        "X = df_train_encoded[['Schooling', 'Adult_Mortality']]\n",
        "y = df_train_encoded['Life_expectancy']\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X,y)\n",
        "\n",
        "y_pred = model.predict(X)\n",
        "r2 = r2_score(y,y_pred)\n",
        "\n",
        "n = len(y)\n",
        "p = X.shape[1]\n",
        "\n",
        "adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
        "\n",
        "# Print Adjusted R2 score\n",
        "print('Adjusted R^2 for model with \"Schooling\", \"Adult_Mortality\" as predictor and \"Life_expectancy\" as outcome is ', adjusted_r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3oT1NbDdRcK"
      },
      "source": [
        "Adjusted $R^2$ for model with \"Schooling\",\"Adult_Mortality\" and \"Population\" as predictor and \"Life_expectancy\" as outcome"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLOFJL2LdVEz"
      },
      "outputs": [],
      "source": [
        "### WRITE CODE ###\n",
        "X = df_train_encoded[['Schooling', 'Adult_Mortality', 'Population']]\n",
        "y = df_train_encoded['Life_expectancy']\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X,y)\n",
        "\n",
        "y_pred = model.predict(X)\n",
        "r2 = r2_score(y,y_pred)\n",
        "\n",
        "n = len(y)\n",
        "p = X.shape[1]\n",
        "\n",
        "adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
        "\n",
        "# Print Adjusted R2 score\n",
        "print('Adjusted R^2 for model with \"Schooling\",\"Adult_Mortality\" and \"Population\" as predictor and \"Life_expectancy\" as outcome is ', adjusted_r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDHU67n8d4x7"
      },
      "source": [
        "### K-fold Cross-Validation\n",
        "\n",
        "However, adjusted $R^2$ is not enough to help us achieve the best model, a more robust method is k-fold cross-validation.\n",
        "\n",
        "* Randomly split dataset into K equal-sized subsets, or folds\n",
        "* Treat each fold as validation set (train on all but K'th fold and test on K'th fold only)\n",
        "\n",
        "* The overall error is then the mean error over all K models.\n",
        "* Most common are 5- or 10-fold cross-validation\n",
        "\n",
        "Please implement a 5-fold cross-validation by yourselves to find the best model in terms of Mean Square Error(MSE)\n",
        "\n",
        "**Do not use sklearn.model_selection.cross_val_score or other built-in cross-validaiton functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnbM2CcZFhWs"
      },
      "outputs": [],
      "source": [
        "# Design a function to implement 5-fold cross-validation.\n",
        "# The input: training features X, training target y and # of folds f=5.\n",
        "# The output: the average of MSE over the 5 folds.\n",
        "\n",
        "lm = LinearRegression()\n",
        "\n",
        "def cross_val_mse(X, y, f):\n",
        "    ### Write your code here ###\n",
        "\n",
        "    shuffled_indices = X.sample(frac=1).index\n",
        "    X = X.loc[shuffled_indices].reset_index(drop=True)\n",
        "    y = y.loc[shuffled_indices].reset_index(drop=True)\n",
        "\n",
        "    size = len(X)//f\n",
        "    mse_arr = []\n",
        "\n",
        "    for i in range(f):\n",
        "        X_val = X[i*size:((i+1)*size)]\n",
        "        X_train_L = X[:i*size]\n",
        "        X_train_R = X[(i+1)*size:]\n",
        "\n",
        "        y_val = y[i*size:((i+1)*size)]\n",
        "        y_train_L = y[:i*size]\n",
        "        y_train_R = y[(i+1)*size:]\n",
        "\n",
        "        X_train = pd.concat([X_train_L, X_train_R], axis=0)\n",
        "        y_train = pd.concat([y_train_L, y_train_R], axis=0)\n",
        "\n",
        "        lm.fit(X_train, y_train)\n",
        "        pred = lm.predict(X_val)\n",
        "        mse_arr.append(mean_squared_error(y_val, pred))\n",
        "\n",
        "    return np.mean(mse_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxURVCdbFuWB"
      },
      "outputs": [],
      "source": [
        "# By using your above functions, find the best combination of features, which has the lowest averaged MSE\n",
        "from itertools import combinations\n",
        "### Write code here ###\n",
        "\n",
        "best_comb = None\n",
        "lowest_mse = 25\n",
        "base_columns = 25\n",
        "\n",
        "X_train = df_train_encoded.drop(columns=['Life_expectancy'])\n",
        "y_train = df_train_encoded['Life_expectancy']\n",
        "\n",
        "# Brute force:\n",
        "for i in range(base_columns, len(X_train.columns)+1):\n",
        "    print('current number of features: ' + str(i))\n",
        "    for c in combinations(X_train.columns, i):\n",
        "        mse = cross_val_mse(X_train, y_train, 5)\n",
        "        if mse < lowest_mse:\n",
        "            lowest_mse = mse\n",
        "            best_comb = c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3WWuFZ-eGGE"
      },
      "outputs": [],
      "source": [
        "# Print the best features and the corresponding mse\n",
        "### WRITE CODE ###\n",
        "\n",
        "print('The best comb of features:' + str(best_comb))\n",
        "print('with ' + str(len(best_comb)) + ' features')\n",
        "print('===')\n",
        "print('Corresponding MSE: ' + str(lowest_mse))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-WBDncGtiY2"
      },
      "source": [
        "### Test your model\n",
        "Now, apply your best model to predict the target values from the test feature set \"LifeExpectancy_test_modified.csv\". We will grade this part based on your prediction error.\n",
        "\n",
        "Hint: Please be careful on standardization and one-hot encoding (if you use), the test set should be consistent with the training set in terms of any transformation.\n",
        "\n",
        "Hint2: You may want to modify the previous steps to make the transformation of the test set consistent with the training set."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_encoded.head()"
      ],
      "metadata": {
        "id": "m8gV-hhhyI5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMjcj9ACoxP4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from statistics import mean\n",
        "from sklearn import datasets\n",
        "import seaborn as sns\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpdkeyXmn0zW"
      },
      "outputs": [],
      "source": [
        "data_features = df_train.drop(\"Life_expectancy\", axis=1)\n",
        "data_target = df_train['Life_expectancy'].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dh7Qzk0qvza0"
      },
      "outputs": [],
      "source": [
        "data_categorical_features = data_features[['Year', 'Status']]\n",
        "data_numerical_features = data_features.drop(['Year', 'Status'], axis=1)\n",
        "\n",
        "# Numerical pipeline\n",
        "num_pipeline = Pipeline([\n",
        "    ('std_scaler', StandardScaler()),\n",
        "])\n",
        "\n",
        "# Specifying the features for each pipeline\n",
        "numerical_features = list(data_numerical_features.columns)\n",
        "categorical_features = list(data_categorical_features.columns)\n",
        "\n",
        "# Creating the full pipeline\n",
        "full_pipeline = ColumnTransformer([\n",
        "    (\"num\", num_pipeline, numerical_features),\n",
        "    (\"cat\", OneHotEncoder(), categorical_features),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vu499xaHoJec"
      },
      "outputs": [],
      "source": [
        "train = full_pipeline.fit_transform(data_features)\n",
        "test = full_pipeline.transform(df_test)\n",
        "\n",
        "model = LinearRegression()\n",
        "\n",
        "model.fit(train, data_target)\n",
        "y_train_pred = model.predict(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmXtmsWfODV_"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "mse_train = mean_squared_error(data_target, y_train_pred)\n",
        "print(\"Mean Squared Error on Training Set:\", mse_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiAjaO3BOUWk"
      },
      "outputs": [],
      "source": [
        "transformed_numerical_features = numerical_features\n",
        "\n",
        "# For categorical features, we need to get the new column names from the one-hot encoder\n",
        "# We need to access the 'cat' transformer from the ColumnTransformer, then the OneHotEncoder itself\n",
        "onehot_columns = list(full_pipeline.named_transformers_['cat'].get_feature_names_out(categorical_features))\n",
        "\n",
        "transformed_feature_names = transformed_numerical_features + onehot_columns\n",
        "\n",
        "coefficients_df = pd.DataFrame({\n",
        "    'Feature': transformed_feature_names,\n",
        "    'Coefficient': model.coef_\n",
        "})\n",
        "\n",
        "coefficients_df['Coefficient'] = coefficients_df['Coefficient'].apply(lambda x: f'{x:.4f}')\n",
        "\n",
        "# Sort the DataFrame by 'Coefficient' in descending order (from highest to lowest)\n",
        "coefficients_df_sorted = coefficients_df.sort_values(by='Coefficient', ascending=False)\n",
        "\n",
        "coefficients_df_sorted = coefficients_df_sorted.reset_index(drop=True)\n",
        "\n",
        "coefficients_df_sorted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5tP0PG4OcsO"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "# Convert the transformed training data to a DataFrame\n",
        "train_df = pd.DataFrame(train, columns=transformed_feature_names)\n",
        "\n",
        "# Add a constant to the DataFrame for the intercept\n",
        "train_df_with_const = sm.add_constant(train_df, prepend=True)\n",
        "train_df_with_const = train_df_with_const.rename(columns={0: 'Intercept'})\n",
        "\n",
        "# Create the OLS model with statsmodels using the DataFrame\n",
        "ols_model = sm.OLS(data_target, train_df_with_const)\n",
        "\n",
        "# Fit the model\n",
        "results = ols_model.fit()\n",
        "\n",
        "# Print out the statistics\n",
        "model_summary = results.summary()\n",
        "print(model_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmDeO4SOOejL"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "# Initialize RFE with the linear regression model\n",
        "selector = RFE(model, n_features_to_select=1, step=1)\n",
        "\n",
        "# Fit RFE\n",
        "selector = selector.fit(train, data_target)\n",
        "\n",
        "# These are the features selected by RFE\n",
        "selected_features = np.array(transformed_feature_names)[selector.support_]\n",
        "\n",
        "# Get the ranking of the features\n",
        "ranking = selector.ranking_\n",
        "\n",
        "# Create a DataFrame to display feature ranking\n",
        "ranking_df = pd.DataFrame({\n",
        "    'Feature': transformed_feature_names,\n",
        "    'Ranking': ranking\n",
        "})\n",
        "\n",
        "# Sort the DataFrame based on the ranking\n",
        "ranking_df_sorted = ranking_df.sort_values(by='Ranking')\n",
        "\n",
        "# Print the ranking of features\n",
        "print(ranking_df_sorted)\n",
        "\n",
        "# If you wish to train the model only on selected features\n",
        "# Filter the training and test sets for selected features\n",
        "train_selected = selector.transform(train)\n",
        "test_selected = selector.transform(test)\n",
        "\n",
        "# Create a new model using only the selected features\n",
        "model_selected = LinearRegression()\n",
        "model_selected.fit(train_selected, data_target)\n",
        "\n",
        "# Predict and evaluate the model as before\n",
        "y_train_pred_selected = model_selected.predict(train_selected)\n",
        "mse_train_selected = mean_squared_error(data_target, y_train_pred_selected)\n",
        "print(\"Mean Squared Error on Training Set with selected features:\", mse_train_selected)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfuZ91KHOqGj"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Dictionary to store the MSE for each feature\n",
        "brute_force_results = {}\n",
        "\n",
        "# Loop over each feature in the dataset\n",
        "for feature in transformed_feature_names:\n",
        "    # Select only the current feature for training\n",
        "    feature_index = transformed_feature_names.index(feature)\n",
        "    X_train_feature = train[:, feature_index].reshape(-1, 1)\n",
        "\n",
        "    # Train the model using only the current feature\n",
        "    single_feature_model = LinearRegression()\n",
        "    single_feature_model.fit(X_train_feature, data_target)\n",
        "\n",
        "    # Predict on the training data\n",
        "    y_train_pred_feature = single_feature_model.predict(X_train_feature)\n",
        "\n",
        "    # Calculate the mean squared error\n",
        "    mse_feature = mean_squared_error(data_target, y_train_pred_feature)\n",
        "    brute_force_results[feature] = mse_feature\n",
        "\n",
        "# Sort the results to find the most predictive features (lowest MSE)\n",
        "sorted_brute_force_results = sorted(brute_force_results.items(), key=lambda x: x[1])\n",
        "\n",
        "# Display the sorted results\n",
        "for feature, mse in sorted_brute_force_results:\n",
        "    print(f'Feature: {feature}, MSE: {mse}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "My8fPcKPPE5W"
      },
      "outputs": [],
      "source": [
        "#Selected features with lowest p-value, best RFE scores, and lowest MSE\n",
        "X = df_train[['Schooling', 'HIV_AIDS', 'Income_composition_of_resources', 'Adult_Mortality']]\n",
        "y = df_train['Life_expectancy']\n",
        "\n",
        "#Train the model with selected features\n",
        "model = LinearRegression()\n",
        "model.fit(X,y)\n",
        "\n",
        "#Predict on the test set with selected features\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "#Calculate the mean squared error on the test set\n",
        "mse_test = mean_squared_error(data_target, y_pred)\n",
        "print(\"Mean Squared Error on Test Set with selected features:\", mse_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPfqPkQ2vbq7"
      },
      "outputs": [],
      "source": [
        "#end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR3Of1DvZbgf"
      },
      "source": [
        "### Individual student contribution\n",
        "Student 1 Joy Lin - Q1-Q6 </br>\n",
        "Student 2 Yash Garg - Q7-Q9 </br>\n",
        "Student 3 Binglei Roger Zhang - Goodness of fit </br>\n",
        "Student 4 Steven Chen - K-fold Cross-Validation </br>\n",
        "Student 5 Helen Chen - Test Your Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdp4oizZZbgg"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}